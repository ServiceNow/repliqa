{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict, Any\n",
    "import datasets\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get API key\n",
    "## We rely on https://openrouter.ai/ to run inference on multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENROUTER_API_KEY = os.environ.get(\"OPENROUTER_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QA processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAEvaluator:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str,\n",
    "        openrouter_api_key: str,\n",
    "        n_trials: int = 1,\n",
    "        sleep_time_between_retrials: float = 1.0,\n",
    "        max_sleep_time_between_retrials: float = 600.0,\n",
    "    ) -> None:\n",
    "\n",
    "        self.model_name = model_name\n",
    "        self._base_system_prompt = (\n",
    "            \"You are an expert research assistant, skilled in answering questions \"\n",
    "            \"concisely and precisely, using information provided by the user. \"\n",
    "        )\n",
    "        self._base_user_prompt = (\n",
    "            \"I'd like for you to answer questions about a context text that will be provided.\"\n",
    "            \"I'll give you a pair with the form:\\nContext: 'context text'\\nQuestion: 'a question about the context'.\\n\"\n",
    "            \"First, tell me about your knowledge of the context and what information it contains, \"\n",
    "            \"then, create an analysis of the context strictly using information contained in the text provided. \"\n",
    "            \"Your knowledge about the context and the analysis must not be output. \"\n",
    "            \"Finally, generate an explicit answer to the question that will be output. \"\n",
    "            \"Make sure that the answer is the only output you provide, and the analysis of the context should be kept to yourself. \"\n",
    "            \"Answer directly and do not prefix the answer with anything such as 'Answer:' nor 'The answer is:'. \"\n",
    "            \"The answer has to be the only output you explicitly provide. \"\n",
    "            \"The answer has to be as short, direct, and concise as possible. \"\n",
    "            \"If the answer to the question can not be obtained from the provided context paragraph, output 'UNANSWERABLE'. \"\n",
    "            \"Here's the context and question for you to reason about and answer:\\n\"\n",
    "        )\n",
    "\n",
    "        self.n_trials = n_trials\n",
    "        self.sleep_time_between_retrials = sleep_time_between_retrials\n",
    "        self.max_sleep_time_between_retrials = max_sleep_time_between_retrials\n",
    "\n",
    "        self._openrouter_api_key = openrouter_api_key\n",
    "\n",
    "    def __call__(self, example: Dict[str, Any]) -> Dict[str, Any]:\n",
    "\n",
    "        if \"document_extracted\" in example:\n",
    "            context_str = example[\"document_extracted\"]\n",
    "        elif \"entity_pages\":\n",
    "            context_str = (\"\\n\\n\").join(example[\"entity_pages\"][\"wiki_context\"])\n",
    "        else:\n",
    "            raise ValueError(\"Unknonw data format. Can't read 'context' or 'entity_pages' fields.\")\n",
    "        question_str = example[\"question\"]\n",
    "        system_prompt_str = self._base_system_prompt\n",
    "        user_prompt_str = (\n",
    "            self._base_user_prompt + f\"Context: {context_str}\\nQuestion: {question_str}?\\n\"\n",
    "        )\n",
    "\n",
    "        for trial in range(self.n_trials):\n",
    "\n",
    "            try:\n",
    "                model_response = requests.post(\n",
    "                    url=\"https://openrouter.ai/api/v1/chat/completions\",\n",
    "                    headers={\n",
    "                        \"Authorization\": f\"Bearer {self._openrouter_api_key}\",\n",
    "                    },\n",
    "                    data=json.dumps(\n",
    "                        {\n",
    "                            \"model\": self.model_name,\n",
    "                            \"messages\": [\n",
    "                                {\n",
    "                                    \"role\": \"system\",\n",
    "                                    \"content\": system_prompt_str,\n",
    "                                },\n",
    "                                {\"role\": \"user\", \"content\": user_prompt_str},\n",
    "                            ],\n",
    "                        }\n",
    "                    ),\n",
    "                )\n",
    "\n",
    "                raw_response = model_response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "                break\n",
    "            except (\n",
    "                KeyError,\n",
    "                IndexError,\n",
    "                json.JSONDecodeError,\n",
    "                requests.exceptions.ConnectionError,\n",
    "                requests.exceptions.ChunkedEncodingError,\n",
    "            ) as e:\n",
    "                print(f\"Trial: {trial}: {e}\")\n",
    "                raw_response = \"ERROR\"\n",
    "                sleep_time = min(\n",
    "                    self.max_sleep_time_between_retrials,\n",
    "                    self.sleep_time_between_retrials * (2 ** (trial + 1)),\n",
    "                )\n",
    "                time.sleep(sleep_time)\n",
    "\n",
    "        return {\n",
    "            \"answer_pred\": raw_response,\n",
    "            \"cleaned_answer_pred\": self.process_answer(raw_response),\n",
    "            \"model_name\": self.model_name,\n",
    "        }\n",
    "\n",
    "    def process_answer(self, raw_answer: str) -> str:\n",
    "        return raw_answer.split(\":\")[-1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text classification processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopicRetrievalEvaluator:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str,\n",
    "        topics: str,\n",
    "        openrouter_api_key: str,\n",
    "        n_trials: int = 1,\n",
    "        sleep_time_between_retrials: float = 1.0,\n",
    "        max_sleep_time_between_retrials: float = 600.0,\n",
    "    ) -> None:\n",
    "\n",
    "        self.model_name = model_name\n",
    "\n",
    "        self._base_system_prompt = (\n",
    "            \"You are an expert research assistant, skilled in answering questions \"\n",
    "            \"concisely and precisely, using information provided by the user. \"\n",
    "        )\n",
    "        self._base_user_prompt = (\n",
    "            \"I'd like for you to determine the topic of some text context that will be provided.\"\n",
    "            \"I'll give you the text with the form:\\nContext: 'text'.\\n\"\n",
    "            \"First, tell me about your knowledge of the context and what information it contains, \"\n",
    "            \"then, create an analysis of the context strictly using information contained in the text provided. \"\n",
    "            \"Your knowledge about the context and the analysis must not be output. \"\n",
    "            \"Finally, generate an explicit topic of the ceontext by choosing from the following list of topics: \"\n",
    "            f\"{topics}. \"\n",
    "            \"Make sure that the topic is the only output you provide, and the analysis of the context should be kept to yourself. \"\n",
    "            \"Answer directly with the topic from the list, and do not prefix the answer with anything such as 'Answer:' nor 'Topic:'. \"\n",
    "            \"The topic has to be the only output you explicitly provide. \"\n",
    "            \"your output has to be as short, direct, and concise as possible. \"\n",
    "            \"The answer strictly has to be one of the topics provided to you. \"\n",
    "            \"If the topic cannot be obtained from the provided context paragraph, output 'UNANSWERABLE'. \"\n",
    "            \"Here's the context for you to determine the topic:\\n\"\n",
    "        )\n",
    "\n",
    "        self.n_trials = n_trials\n",
    "        self.sleep_time_between_retrials = sleep_time_between_retrials\n",
    "        self.max_sleep_time_between_retrials = max_sleep_time_between_retrials\n",
    "\n",
    "        self._openrouter_api_key = openrouter_api_key\n",
    "\n",
    "    def __call__(self, example: Dict[str, Any]) -> Dict[str, Any]:\n",
    "\n",
    "        context_str = example[\"document_extracted\"]\n",
    "        system_prompt_str = self._base_system_prompt\n",
    "        user_prompt_str = self._base_user_prompt + f\"Context: {context_str}\\n\"\n",
    "\n",
    "        for trial in range(self.n_trials):\n",
    "\n",
    "            try:\n",
    "                model_response = requests.post(\n",
    "                    url=\"https://openrouter.ai/api/v1/chat/completions\",\n",
    "                    headers={\n",
    "                        \"Authorization\": f\"Bearer {self._openrouter_api_key}\",\n",
    "                    },\n",
    "                    data=json.dumps(\n",
    "                        {\n",
    "                            \"model\": self.model_name,\n",
    "                            \"messages\": [\n",
    "                                {\n",
    "                                    \"role\": \"system\",\n",
    "                                    \"content\": system_prompt_str,\n",
    "                                },\n",
    "                                {\"role\": \"user\", \"content\": user_prompt_str},\n",
    "                            ],\n",
    "                        }\n",
    "                    ),\n",
    "                )\n",
    "\n",
    "                raw_response = model_response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "                break\n",
    "            except (\n",
    "                KeyError,\n",
    "                IndexError,\n",
    "                json.JSONDecodeError,\n",
    "                requests.exceptions.ConnectionError,\n",
    "                requests.exceptions.ChunkedEncodingError,\n",
    "            ) as e:\n",
    "                print(f\"Trial: {trial}: {e}\")\n",
    "                raw_response = \"ERROR\"\n",
    "                sleep_time = min(\n",
    "                    self.max_sleep_time_between_retrials,\n",
    "                    self.sleep_time_between_retrials * (2 ** (trial + 1)),\n",
    "                )\n",
    "                time.sleep(sleep_time)\n",
    "\n",
    "        return {\n",
    "            \"full_answer_retrieved_topic\": raw_response,\n",
    "            \"cleaned_answer_retrieved_topic\": self.process_answer(raw_response),\n",
    "            \"model_name\": self.model_name,\n",
    "        }\n",
    "\n",
    "    def process_answer(self, raw_answer: str) -> str:\n",
    "        return raw_answer.split(\":\")[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List models to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available models are listed at: https://openrouter.ai/models\n",
    "models = [\"mistralai/mistral-7b-instruct\", \"meta-llama/llama-3-8b-instruct\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get set of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repliqa = datasets.load_dataset(\"ServiceNow/repliqa\")[\"repliqa_0\"]\n",
    "topics = list(np.unique(repliqa[\"document_topic\"]))\n",
    "topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_datasets = {}\n",
    "N_RETRIALS = 5  # Maximum number of re-attempts after failed inference requests\n",
    "\n",
    "for model in tqdm.tqdm(models, total=len(models), desc=\"Models\"):\n",
    "\n",
    "  repliqa = datasets.load_dataset(\"ServiceNow/repliqa\")[\"repliqa_0\"].select(range(10))\n",
    "\n",
    "  qa_pre_processor = QAEvaluator(model, OPENROUTER_API_KEY, n_trials=N_RETRIALS)\n",
    "  topic_retriever_pre_processor = TopicRetrievalEvaluator(model, topics, OPENROUTER_API_KEY, n_trials=N_RETRIALS)\n",
    "\n",
    "  prediction_dataset = repliqa.map(qa_pre_processor)\n",
    "  prediction_dataset = prediction_dataset.map(topic_retriever_pre_processor)\n",
    "\n",
    "  inference_datasets[model] = prediction_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
